{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravind2060/Retail_Sales_Analytics_and_Demand_Forecasting/blob/master/Retail_Sales_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n"
      ],
      "metadata": {
        "id": "Gh9TPO5uFgpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project provides hands-on experience in building a large-scale data processing pipeline for demand forecasting, customer sentiment analysis, and real-time analytics for a retail company. It integrates historical data analysis, real-time monitoring, and predictive modeling, creating a complex workflow.\n",
        "\n",
        "Objectives\n",
        "\n",
        "* Process, analyze, and visualize historical retail data\n",
        "* Forecast demand and analyze customer sentiment\n",
        "* Implement real-time transaction monitoring using Spark Streaming\n",
        "\n"
      ],
      "metadata": {
        "id": "IK3zfaMIFszE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q46UHdtJF3eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 : Data Loading, Cleansing, and Exploration"
      ],
      "metadata": {
        "id": "B3Fm4PNjGTgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *Data Ingestion* : Load the sales and review datasets into PySpark. DataFrames, Explore and check for missing or inconsistent data.\n",
        "* *Data Cleansing* : Handle missing values, drop duplicates, and parse dates for consistent data."
      ],
      "metadata": {
        "id": "-51thfW2GiCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# !pip install ucimlrepo\n",
        "\n",
        "# from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# # fetch dataset\n",
        "# online_retail = fetch_ucirepo(id=352)\n",
        "\n",
        "# # data (as pandas dataframes)\n",
        "# X = online_retail.data.features\n",
        "# y = online_retail.data.targets\n",
        "\n",
        "# # metadata\n",
        "# print(online_retail.metadata)\n",
        "\n",
        "# print(X)\n",
        "# print(y)\n",
        "\n",
        "# # variable information\n",
        "# print(online_retail.variables)"
      ],
      "metadata": {
        "id": "3Wc_t7qyWaWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading Historical Sales data: – Contains sales transaction data for an online retail store.\n",
        "# More Info : https://archive.ics.uci.edu/dataset/352/online+retail\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "historical_sales_data_path =\"https://archive.ics.uci.edu/static/public/352/data.csv\";\n",
        "\n",
        "historical_sales_df = pd.read_csv(historical_sales_data_path)\n",
        "\n",
        "# print(historical_sales_df.info())\n",
        "print(historical_sales_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU6s8jYyHQbA",
        "outputId": "2f7fb164-07f6-452f-a399-80a80bac7b48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
            "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
            "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
            "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
            "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading Customer Reviews Data: – Includes detailed customer review data for sentiment analysis.\n",
        "# More information : https://registry.opendata.aws/helpful-sentences-from-reviews/\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Define the URLs for the train and test files\n",
        "train_file_path = \"https://helpful-sentences-from-reviews.s3.amazonaws.com/train.json\"\n",
        "test_file_path  = \"https://helpful-sentences-from-reviews.s3.amazonaws.com/test.json\"\n",
        "\n",
        "# Function to load JSON from a URL where each line is a separate JSON object\n",
        "def load_json_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    data = []\n",
        "\n",
        "    # Read each line from the response text as a separate JSON object\n",
        "    for line in response.text.splitlines():\n",
        "        try:\n",
        "            data.append(json.loads(line))  # Convert each line into a dictionary\n",
        "        except json.JSONDecodeError:\n",
        "            # Skip invalid lines if any, or handle them differently if needed\n",
        "            continue\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load the train data\n",
        "train_data = load_json_from_url(train_file_path)\n",
        "train_df = pd.DataFrame(train_data)\n",
        "\n",
        "# Load the test data\n",
        "test_data = load_json_from_url(test_file_path)\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "# Print the first few rows of the train DataFrame\n",
        "print(train_df.head())\n",
        "\n",
        "# Optionally, print the test DataFrame as well\n",
        "# print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTepzWgGHiWu",
        "outputId": "9ef849db-7fa3-4633-9218-1817de14abda"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         asin                                           sentence  helpful  \\\n",
            "0  B000AO3L84                      this flash is a superb value.     1.70   \n",
            "1  B001SEQPGK                The pictures were not sharp at all.     1.30   \n",
            "2  0553386697                  A very good resource for parents.     1.90   \n",
            "3  B006SUWZH2  We have it in a child's room, and will be swit...     0.25   \n",
            "4  B000W7F5SS  Again the makers are too lazy to bring in the ...     0.90   \n",
            "\n",
            "                                      main_image_url  \\\n",
            "0  http://ecx.images-amazon.com/images/I/41XAEKR9...   \n",
            "1  http://ecx.images-amazon.com/images/I/71KLvmtc...   \n",
            "2  http://ecx.images-amazon.com/images/I/81HdbmkR...   \n",
            "3  http://ecx.images-amazon.com/images/I/61A2WQOL...   \n",
            "4  http://ecx.images-amazon.com/images/I/91E7TPDb...   \n",
            "\n",
            "                                       product_title  \n",
            "0  Canon 430EX Speedlite Flash for Canon EOS SLR ...  \n",
            "1  Sony Cyber-shot DSC-W290 12 MP Digital Camera ...  \n",
            "2  The Whole-Brain Child: 12 Revolutionary Strate...  \n",
            "3       Memorex Portable CD Boombox with AM FM Radio  \n",
            "4  Harry Potter and the Order of the Phoenix (Wid...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for Any null values"
      ],
      "metadata": {
        "id": "OXieYqJlSXYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for null columns in historical_sales_df\n",
        "missing_columns = historical_sales_df.columns[historical_sales_df.isnull().any()].tolist()\n",
        "print(\"Null columns in historical sales: \",missing_columns)\n",
        "\n",
        "#no.of missing rows in each column\n",
        "print(historical_sales_df.isnull().sum())\n",
        "\n",
        "\n",
        "#Checking for null columns in customer reviews\n",
        "missing_columns = train_df.columns[train_df.isnull().any()].tolist()\n",
        "print(\"Null columns in train_df \",missing_columns)\n",
        "\n",
        "#Checking for null Columns in Customer reviews\n",
        "missing_columns = test_df.columns[test_df.isnull().any()].tolist()\n",
        "print(\"Null columns in test_df \",missing_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7GtO17ySbp2",
        "outputId": "434d3a4b-0cfc-4066-b570-fcb3257e3c2c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null columns in historical sales:  ['Description', 'CustomerID']\n",
            "InvoiceNo           0\n",
            "StockCode           0\n",
            "Description      1454\n",
            "Quantity            0\n",
            "InvoiceDate         0\n",
            "UnitPrice           0\n",
            "CustomerID     135080\n",
            "Country             0\n",
            "dtype: int64\n",
            "Null columns in train_df  []\n",
            "Null columns in test_df  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping null rows\n",
        "\n",
        "historical_sales_df = historical_sales_df.dropna()\n",
        "\n",
        "print(historical_sales_df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhoSadBYcrTO",
        "outputId": "1684ad5e-cecd-4b45-b475-802140493cb1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InvoiceNo      0\n",
            "StockCode      0\n",
            "Description    0\n",
            "Quantity       0\n",
            "InvoiceDate    0\n",
            "UnitPrice      0\n",
            "CustomerID     0\n",
            "Country        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6u4CF-xbd4iS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}